{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Proper audience targeting is a critical component of a successful advertising campaign. This notebook aims to identify customer demographics that may be particularly receptive to Game Revenant's (GR) advertising. Analysis is performed on unstructured social media data, specifically from Twitter. Compared to other social media, Twitter's API allows greater access to user data, enabling more effective data mining. \n",
    "\n",
    "GR currently has too few followers on Twitter to allow for productive data mining. However, the Twitter accounts of rival companies can be analyzed as well. *Where Shadows Slumber* (WSS) is frequently compared to *Monument Valley*, a mobile puzzle game produced by USTWO Games, by game critics and customer reviewers. As of this writing, @ustwogames has over 126k followers. \n",
    "\n",
    "Customer interests were estimated by 1) examining the profile description of @ustogames followers, and 2) examining the most popular friends among @ustogames followers. Preprocessed descriptions were examined via two clustering approches, K-modes and \n",
    "DBSCAN. In Twitter's official terminology, a 'friend' is an account a user follows. The most popular friends were clustered via K-modes. The rationale behind the unorthodox application of K-modes will be explained later in the notebook. \n",
    "\n",
    "## Methods and Results\n",
    "\n",
    "The Twitter profiles of @ustogames were mined via the python package Tweepy and written to a SQL database (refer to *pull_data_twitter.py* and *sqlite_fx.py* for script and function codes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vincent S\\game-revenant\\Customer-Segmentation\n"
     ]
    }
   ],
   "source": [
    "# Autoreload to accomodate script updates without restarting notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Move to main directory of the Customer-Segmentation project\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>id_string</th>\n",
       "      <th>name</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friend_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1114109046792032256</td>\n",
       "      <td>1114109046792032256</td>\n",
       "      <td>Hiyoru</td>\n",
       "      <td>Hiyoru6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>so para fotos de desenhos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>5</td>\n",
       "      <td>Fri Apr 05 10:14:30 +0000 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1120790192128954371</td>\n",
       "      <td>1120790192128954371</td>\n",
       "      <td>Tom Baines üè≥Ô∏è‚Äçüåà üá™üá∫</td>\n",
       "      <td>TomBaines16</td>\n",
       "      <td>North West, England</td>\n",
       "      <td>None</td>\n",
       "      <td>Extreme sports calendar model. \\nKeeping retro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "      <td>456</td>\n",
       "      <td>Tue Apr 23 20:42:59 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>113652889</td>\n",
       "      <td>113652889</td>\n",
       "      <td>Marmalade Games</td>\n",
       "      <td>MarmaladeGames</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>http://t.co/sPUf5LShHE</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>506</td>\n",
       "      <td>262</td>\n",
       "      <td>13</td>\n",
       "      <td>304</td>\n",
       "      <td>471</td>\n",
       "      <td>Fri Feb 12 15:07:07 +0000 2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>363116063</td>\n",
       "      <td>363116063</td>\n",
       "      <td>MIT SHAH</td>\n",
       "      <td>mitshah97</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>None</td>\n",
       "      <td>#Unity3d #Game #Developer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>Sat Aug 27 15:13:29 +0000 2011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>972169508</td>\n",
       "      <td>972169508</td>\n",
       "      <td>Kyrie E.H.C.</td>\n",
       "      <td>KyrieEHC</td>\n",
       "      <td>Madison, WI</td>\n",
       "      <td>https://t.co/ajE03P8x2g</td>\n",
       "      <td>Still believes in the warmth in interaction. S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>1103</td>\n",
       "      <td>18</td>\n",
       "      <td>1118</td>\n",
       "      <td>734</td>\n",
       "      <td>Mon Nov 26 15:27:59 +0000 2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                   id            id_string                name  \\\n",
       "0      0  1114109046792032256  1114109046792032256              Hiyoru   \n",
       "1      1  1120790192128954371  1120790192128954371  Tom Baines üè≥Ô∏è‚Äçüåà üá™üá∫   \n",
       "2      2            113652889            113652889     Marmalade Games   \n",
       "3      3            363116063            363116063            MIT SHAH   \n",
       "4      4            972169508            972169508        Kyrie E.H.C.   \n",
       "\n",
       "      screen_name             location                      url  \\\n",
       "0         Hiyoru6                 None                     None   \n",
       "1     TomBaines16  North West, England                     None   \n",
       "2  MarmaladeGames           London, UK   http://t.co/sPUf5LShHE   \n",
       "3       mitshah97            Ahmedabad                     None   \n",
       "4        KyrieEHC          Madison, WI  https://t.co/ajE03P8x2g   \n",
       "\n",
       "                                         description  protected  verified  \\\n",
       "0                          so para fotos de desenhos          0         0   \n",
       "1  Extreme sports calendar model. \\nKeeping retro...          0         0   \n",
       "2                                               None          0         0   \n",
       "3                          #Unity3d #Game #Developer          0         0   \n",
       "4  Still believes in the warmth in interaction. S...          0         0   \n",
       "\n",
       "   followers_count  friend_count  listed_count  favourites_count  \\\n",
       "0                1            21             0               139   \n",
       "1               29           169             0               961   \n",
       "2              506           262            13               304   \n",
       "3               39           279             1                22   \n",
       "4              333          1103            18              1118   \n",
       "\n",
       "   statuses_count                      created_at  default_profile  \\\n",
       "0               5  Fri Apr 05 10:14:30 +0000 2019                1   \n",
       "1             456  Tue Apr 23 20:42:59 +0000 2019                0   \n",
       "2             471  Fri Feb 12 15:07:07 +0000 2010                0   \n",
       "3              13  Sat Aug 27 15:13:29 +0000 2011                1   \n",
       "4             734  Mon Nov 26 15:27:59 +0000 2012                0   \n",
       "\n",
       "   default_profile_image  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from pathlib import Path\n",
    "\n",
    "DB_NAME = 'customer-segmentation'\n",
    "TAB_NAME = 'ustwo_followers'\n",
    "\n",
    "# Pull interim data from SQLite DB\n",
    "e = sa.create_engine('sqlite:///./data/interim/' + DB_NAME + '.sqlite')\n",
    "query = 'SELECT * FROM ' + TAB_NAME\n",
    "users = pd.read_sql_query(query, e)\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125925 @ustwogames follower profiles were mined\n"
     ]
    }
   ],
   "source": [
    "print(str(len(users)) + ' @ustwogames follower profiles were mined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text wrangling of profile descriptions\n",
    "\n",
    "Although a number of parameters were mined, only the profile description and identifying user id are of interest in the proceeding analysis. \n",
    "\n",
    "Prior to analysis, unstructured text data must be preprocessed. Punctuation, emojis, and excess white space were removed. All words were converted to lowercase and tokenized. Stopwords were removed. The NLTK stopword list was extended by several words that were found to be common in profile descriptions, but did not add any useful information about user interests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so para fotos de desenhos</td>\n",
       "      <td>para fotos de desenhos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extreme sports calendar model. \\nKeeping retro...</td>\n",
       "      <td>extreme sports calendar model keeping retro al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Unity3d #Game #Developer</td>\n",
       "      <td>unity game developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Still believes in the warmth in interaction. S...</td>\n",
       "      <td>still believes warmth interaction studied game...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                          so para fotos de desenhos   \n",
       "1  Extreme sports calendar model. \\nKeeping retro...   \n",
       "2                                               None   \n",
       "3                          #Unity3d #Game #Developer   \n",
       "4  Still believes in the warmth in interaction. S...   \n",
       "\n",
       "                                          clean_desc  \n",
       "0                             para fotos de desenhos  \n",
       "1  extreme sports calendar model keeping retro al...  \n",
       "2                                                NaN  \n",
       "3                               unity game developer  \n",
       "4  still believes warmth interaction studied game...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def normalize_doc(doc, stop_words):\n",
    "    # remove special characters and white space. This filters out non-Latin languages!!\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', ' ', doc, re.IGNORECASE|re.ASCII)\n",
    "    # remove single characters\n",
    "    doc = re.sub(r'\\b[a-zA-Z]\\b', '', doc, re.IGNORECASE|re.ASCII)    \n",
    "    # remove whitespace at beginning and end of string\n",
    "    doc = doc.strip()\n",
    "    # convert all characters to lowercase\n",
    "    doc = doc.lower()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # recreate doc from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.extend(['co', 'https', 'http', 'gmail', 'com', 'like', 'love'])\n",
    "\n",
    "users['clean_desc'] = users['description'].map(lambda doc: normalize_doc(doc, stop_words) \n",
    "                                                if doc is not None\n",
    "                                                else np.nan)\n",
    "\n",
    "users[['description','clean_desc']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, only profile descriptions in English were analyzed. Language identification of short text is challenging, and the more common language identication libraries (e.g. langid) were inaccurately classifying certain profile descriptions. Facebook's FastText library offers an alternative that has shown relatively high accuracy with short text language classification (http://alexott.blogspot.com/2017/10/evaluating-fasttexts-models-for.html). \n",
    "\n",
    "English profiles were lemmatized using the NLP libary spaCy, completing the text preprocessing stage of the analysis pipeline. Lemmatization can take several minutes, so the updated DataFrame was saved to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4fba4de83ef8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#download 'small' version of english model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fasttext\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en') #download 'small' version of english model\n",
    "\n",
    "def lemmatize_doc(doc):\n",
    "    doc = nlp(doc)\n",
    "    doc = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in doc])\n",
    "    return doc\n",
    "\n",
    "# import and apply FastText model for language identification\n",
    "idlang_path = 'data/external/fasttext_training_data/lid.176.bin'\n",
    "idlang_model = fasttext.FastText.load_model(idlang_path)\n",
    "\n",
    "users['lang_id'] = users['clean_desc'].map(lambda doc: idlang_model.predict(doc) \n",
    "                                            if doc == doc \n",
    "                                            else np.nan)\n",
    "\n",
    "# only English profiles are lemmatized; empty profiles are also ignored\n",
    "users['clean_desc_en'] = users.apply(lambda row: lemmatize_doc(row['clean_desc']) \n",
    "                                        if  row['lang_id'] == row['lang_id']\n",
    "                                        and row['lang_id'][0][0] == '__label__en'\n",
    "                                        and row['clean_desc'] == row['clean_desc'] \n",
    "                                        else np.nan,\n",
    "                                        axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>clean_desc</th>\n",
       "      <th>clean_desc_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so para fotos de desenhos</td>\n",
       "      <td>para fotos de desenhos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extreme sports calendar model. \\nKeeping retro...</td>\n",
       "      <td>extreme sports calendar model keeping retro al...</td>\n",
       "      <td>extreme sport calendar model keep retro alive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Unity3d #Game #Developer</td>\n",
       "      <td>unity game developer</td>\n",
       "      <td>unity game developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Still believes in the warmth in interaction. S...</td>\n",
       "      <td>still believes warmth interaction studied game...</td>\n",
       "      <td>still believe warmth interaction study game cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0                          so para fotos de desenhos   \n",
       "1  Extreme sports calendar model. \\nKeeping retro...   \n",
       "2                                               None   \n",
       "3                          #Unity3d #Game #Developer   \n",
       "4  Still believes in the warmth in interaction. S...   \n",
       "\n",
       "                                          clean_desc  \\\n",
       "0                             para fotos de desenhos   \n",
       "1  extreme sports calendar model keeping retro al...   \n",
       "2                                                NaN   \n",
       "3                               unity game developer   \n",
       "4  still believes warmth interaction studied game...   \n",
       "\n",
       "                                       clean_desc_en  \n",
       "0                                                NaN  \n",
       "1  extreme sport calendar model keep retro alive ...  \n",
       "2                                                NaN  \n",
       "3                               unity game developer  \n",
       "4  still believe warmth interaction study game cu...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push processed data into SQLite DB. Profiles with non-English or empty descriptions were dropped\n",
    "e = sa.create_engine('sqlite:///./data/processed/' + DB_NAME + '_clean.sqlite')\n",
    "\n",
    "cleaned_tab = TAB_NAME + '_clean'\n",
    "users[['id', 'clean_desc_en']].to_sql(cleaned_tab, e)\n",
    "\n",
    "users[['description','clean_desc','clean_desc_en']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering profile descriptions\n",
    "\n",
    "After preprocessing, the profile descriptions were clustered via two approaches, K-modes and DBSCAN. \n",
    "\n",
    "#### K-modes clustering\n",
    "\n",
    "Given the short length of a typical profile, a word will typically appear no more than once within a given profile description. **It would thus be more approriate to vectorize profile descriptions as binary categorical vectors, as opposed to numeric vectors.** Profile descriptions were count vectorized as binary categorical data, where a value of *1* would indicate that a given word was present in a given profile description.  \n",
    "\n",
    "\n",
    "K-means is likely the most popular approach to clustering. However, its use is limited to numerical data. The K-modes algorithim was developed as an analog to K-means for categorical data (Huang 1997, 1998). Like K-means, the K-modes algorithim requires that the number of clusters be predetermined.  \n",
    "\n",
    "The kmodes Python library was used to perform K-modes clustering. No optimal number of clusters was assumed a priori. Consequently, K-modes clustering for a a range of initial cluster numbers (2 through 20) was executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kmodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c00c35a38dbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkmodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkmodes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKModes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDB_NAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'customer-segmentation'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mTAB_NAME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'ustwo_followers'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kmodes'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "DB_NAME = 'customer-segmentation'\n",
    "TAB_NAME = 'ustwo_followers'\n",
    "\n",
    "# Pull processed data from SQLite DB\n",
    "e = sa.create_engine('sqlite:///./data/processed/' + DB_NAME + '-clean.sqlite')\n",
    "\n",
    "query = 'SELECT id, clean_desc_en FROM ' + TAB_NAME\n",
    "users = pd.read_sql_query(query, e)\n",
    "# desc_valid = users[['id', 'clean_desc_en']].dropna()\n",
    "desc_valid.dropna()\n",
    "\n",
    "# FULL_PATH = os.path.normpath('c:\\\\Users\\\\Vincent\\\\Game-Revenant\\\\Shadows\\\\ustwo_desc_cluste') # save location\n",
    "FULL_PATH = Path('.models/usto_fol_desc_kmodes')\n",
    "MIN_DF = 100 # minimum document frequency. 75, 200, and 400 were also tried\n",
    "FILE_PREFIX = 'kmode_mindf-' + str(MIN_DF) + '_'\n",
    "\n",
    "cv = CountVectorizer(ngram_range=(1, 2), min_df=MIN_DF, max_df=1.0,\n",
    "                     stop_words=stop_words, binary=True)\n",
    "cat_matrix = cv.fit_transform(desc_valid['clean_desc_en'])\n",
    "\n",
    "NUM_CLUSTERS_RNG = 11\n",
    "\n",
    "for n_clusters in range(2, NUM_CLUSTERS_RNG):\n",
    "    results = desc_valid\n",
    "    kmod = KModes(n_clusters=n_clusters, init='Huang', random_state=42, n_jobs=-1)\n",
    "    y_pred = kmod.fit_predict(cat_matrix.toarray())\n",
    "    results['cluster'] = kmod.labels_\n",
    "    # clustering results saved to a csv for easier comparison between number of clusters\n",
    "    filename = FILE_PREFIX + str(n_clusters) + '.csv'\n",
    "    save_loc = os.path.join(FULL_PATH, filename)\n",
    "    results.to_csv(save_loc, index=False)\n",
    "    print('processed cluster #' + str(n_clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "////maybe I don't have to list keyword functions? not really sure I need\n",
    "\n",
    "The Kmodes algorithim will force the data to be organized into the predefined number of clusters. Clusters are not guaranteed to be generated in a meaningful way. \n",
    "\n",
    "In order to gauge the distinctiveness of the clusters, a vocabulary list of the most common unigrams, bigrams, and trigrams within the profile descriptions of a given cluster are generated (*gen_vocab_list*) and ordered by freqeuncy of occurance. The degree of similiarity in the top vocabulary between two clusters is a measure of the of the distance between those clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# function generates a vocab list of unigrams, bigrams, and trigrams found in the corpus of profile descriptions\n",
    "def gen_vocab_list(corpus):\n",
    "    unigrams = [words for doc in corpus for words in doc.split()]\n",
    "    ngrams = [bigram for doc in corpus for bigram in nltk.ngrams(doc.split(), 2)]\n",
    "    bigrams = [token[0] + ' ' + token[1] for token in ngrams]\n",
    "    ngrams = [bigram for doc in corpus for bigram in nltk.ngrams(doc.split(), 3)]\n",
    "    trigrams = [token[0] + ' ' + token[1] + ' ' + token[2] for token in ngrams]\n",
    "    vocab = unigrams + bigrams + trigrams\n",
    "    return vocab\n",
    "\n",
    "# function to order keywords based on their frequency in the corpus\n",
    "# the min_freq argument sets a minimum frequency for a vocabulary word to be considered a keyword\n",
    "def get_freq_keywords(corpus, min_freq):\n",
    "    unigrams = [words for doc in corpus for words in doc.split()]\n",
    "    key_counter = Counter(unigrams).most_common()\n",
    "    keywords = [key[0] for key in key_counter if key[1] >= min_freq]\n",
    "    return keywords\n",
    "\n",
    "# function to detect keywords present in a document (a profile description)\n",
    "def detect_keywords(doc, keywords):\n",
    "    valid_words = [word for word in doc.split() if word in keywords]\n",
    "    valid_words = ' '.join(valid_words)\n",
    "    if not valid_words:\n",
    "        valid_words = np.nan\n",
    "    return valid_words\n",
    "\n",
    "vocab = gen_vocab_list(users['clean_desc_en'].dropna())\n",
    "keywords = get_freq_keywords(users['clean_desc_en'].dropna(), 500)\n",
    "\n",
    "users['keywords'] = users['clean_desc_en'].map(lambda doc: detect_keywords(doc, keywords) \n",
    "                                                if doc is not None \n",
    "                                                else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTER = 9\n",
    "N_KEYWORDS = 10\n",
    "N_DESC = 10\n",
    "\n",
    "PATH = os.path.normpath('c:\\\\Users\\\\Vincent\\\\Game-Revenant\\\\Shadows\\\\ustwo_desc_cluster')\n",
    "FILE_PREFIX = 'kmode_mindf-100_'\n",
    "FULL_PATH = os.path.join(PATH, FILE_PREFIX + str(NUM_CLUSTER) + '.csv')\n",
    "desc_valid = pd.read_csv(FULL_PATH).dropna()\n",
    "n_total = len(desc_valid)\n",
    "\n",
    "#results.rename(columns={'user_id': 'id'})\n",
    "desc_cluster = desc_valid.drop(['clean_desc_en'], axis=1)\n",
    "df = pd.merge(users, desc_cluster, on='id', how='right')\n",
    "\n",
    "#df = pd.merge(users, desc_valid, on='id', how='right') # users v results originally\n",
    "for cluster in range(0, NUM_CLUSTER):\n",
    "    corpus = df.loc[desc_valid['cluster'] == cluster][['description','clean_desc_en','keywords']]\n",
    "    n_corpus = len(corpus)\n",
    "    vocab = gen_vocab_list(corpus['clean_desc_en'])\n",
    "    print('Cluster: ' + str(cluster))\n",
    "    print(str(n_corpus) + ' (' + str(round(n_corpus/n_total*100)) + '%) users with valid description in this cluster')\n",
    "    print(Counter(vocab).most_common(N_KEYWORDS))\n",
    "    print(corpus[['description','keywords']].sample(n=N_DESC))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN clustering\n",
    "\n",
    "DBSCAN (density-based spatial clustering of applications with noise) is a density-based clustering algorithim. Unlike K-modes, which will force each data point to be assigned to a cluster, DBSCAN will mark data in low-density regions as outliers. \n",
    "\n",
    "Descriptions were vectorized by normalized term frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: -1\n",
      "14653 (30%) users with valid description in this cluster\n",
      "[('world', 391), ('founder', 381), ('work', 380), ('tweet', 337), ('get', 328), ('new', 327), ('fan', 316), ('tech', 315), ('team', 303), ('good', 299)]\n",
      "                                                                                   clean_desc_en\n",
      "46921  vivo base de wifi mutant proud                                                           \n",
      "42782  engineer poet optimist hu wbs old boy                                                    \n",
      "5403   sir hunt signal lva currently work sci fi horror light keep us safe buy wishlist cvxwfdns\n",
      "28083  dantdm squid nugget                                                                      \n",
      "47036  hail fly baby elephant uranus                                                            \n",
      "26358  designzz ag member ag part owner                                                         \n",
      "8778   angry pescatarian asu                                                                    \n",
      "23706  lol                                                                                      \n",
      "2402   paypal puma dj fifa pc line                                                              \n",
      "18285  offical twitter clan ruler member moment recruit ruler pyro ruler flame da new ruler tuff\n",
      "\n",
      "\n",
      "Cluster: 0\n",
      "33571 (70%) users with valid description in this cluster\n",
      "[('game', 10230), ('designer', 4115), ('make', 2613), ('developer', 2461), ('design', 2353), ('gamer', 2216), ('artist', 2185), ('video', 2092), ('play', 1971), ('follow', 1763)]\n",
      "                                                                                                                       clean_desc_en\n",
      "47215  guitarist musician composer wide receiver skateboarder doodler video gamer day dreamer                                       \n",
      "34903  independent thinker                                                                                                          \n",
      "29370  indie creative digital agency gaming studio base london                                                                      \n",
      "46687  senior software engineer thrivahealth previously tribe farmdrop                                                              \n",
      "41700  writer artist musician powerpoint product marketing lead microsoft former freelance writer wire huffpo adota opinion         \n",
      "719    wan na retweet art dude                                                                                                      \n",
      "3183   make game make art make story come alive                                                                                     \n",
      "5985   student assign learning                                                                                                      \n",
      "4427   indie game studio create teck kuoch avocadoeldorado couple passion art design tech create unique innovative gaming experience\n",
      "5317   mobile indie game developer gamedev indiedev unity                                                                           \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "DB_NAME = 'customer-segmentation-clean'\n",
    "TAB_NAME = 'ustwo_followers_clean'\n",
    "\n",
    "# Pull processed data from SQLite DB\n",
    "e = sa.create_engine('sqlite:///./data/processed/' + DB_NAME + '.sqlite')\n",
    "\n",
    "#SQL query includes a WHERE statement that filters out NA values and empty strings\n",
    "query = 'SELECT id, clean_desc_en FROM ' + TAB_NAME + ' WHERE clean_desc_en != \\'\\''\n",
    "users = pd.read_sql_query(query, e)\n",
    "N_DESC = 10\n",
    "N_KEYWORDS = 10\n",
    "\n",
    "tf = TfidfVectorizer(use_idf=False)\n",
    "tf_matrix = tf.fit_transform(users['clean_desc_en']) #tf is normalized as opposed to cv\n",
    "\n",
    "dbscan = DBSCAN(eps=1.2, min_samples=1000)\n",
    "\n",
    "y_pred = dbscan.fit_predict(tf_matrix)\n",
    "# results = users[users['clean_desc_en'].notnull()].copy()\n",
    "# results = users.copy()\n",
    "users['cluster'] = dbscan.labels_\n",
    "\n",
    "n_total = len(results)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "for cluster in np.unique(dbscan.labels_):\n",
    "    df = users.loc[users['cluster'] == cluster]\n",
    "    n_corpus = len(df)\n",
    "    vocab = gen_vocab_list(df['clean_desc_en'])\n",
    "    print('Cluster: ' + str(cluster))\n",
    "    print(str(n_corpus) + ' (' + str(round(n_corpus/n_total*100)) + '%) users with valid description in this cluster')\n",
    "    print(Counter(vocab).most_common(N_KEYWORDS))\n",
    "    print(df[['clean_desc_en']].sample(n=N_DESC))\n",
    "    print('\\n')\n",
    "    \n",
    "results.to_csv('dbscan_game_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push processed data into SQLite DB. Profiles with non-English or empty descriptions were dropped\n",
    "DB_RESULTS_NAME = 'customer_segmentation_cluster'\n",
    "TAB_RESULTS_NAME = 'ustwo_followers_'\n",
    "e = sa.create_engine('sqlite:///./models/processed/' + DB_NAME + '.sqlite')\n",
    "\n",
    "cleaned_tab = TAB_NAME + '_clean'\n",
    "users[['id', 'clean_desc_en']].to_sql(cleaned_tab, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('preprocess_ustwo_users.csv')\n",
    "\n",
    "len(users['clean_desc_en'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import fasttext\n",
    "import spacy\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
